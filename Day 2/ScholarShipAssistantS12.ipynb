{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX9tfCuKw_xg",
        "outputId": "7a5d028f-c8d3-4c5c-a6bb-09ab3772ff47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain==0.3.27 langchain-community==0.3.31 langchain_google_genai==2.1.12 langchain-core==0.3.79 faiss-cpu==1.12.0 python-dotenv==1.1.1 pypdf==6.1.2 serpapi==0.1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2t-KVrmNEqG",
        "outputId": "8c210334-d76a-4f40-cf84-784327086579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.27\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: langchain-community\n",
            "---\n",
            "Name: langchain-community\n",
            "Version: 0.3.31\n",
            "Summary: Community contributed LangChain integrations.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n",
            "---\n",
            "Name: langchain-google-genai\n",
            "Version: 2.1.12\n",
            "Summary: An integration package connecting Google's genai package and LangChain\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filetype, google-ai-generativelanguage, langchain-core, pydantic\n",
            "Required-by: \n",
            "---\n",
            "Name: langchain-core\n",
            "Version: 0.3.79\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity, typing-extensions\n",
            "Required-by: langchain, langchain-community, langchain-google-genai, langchain-text-splitters\n",
            "---\n",
            "Name: faiss-cpu\n",
            "Version: 1.12.0\n",
            "Summary: A library for efficient similarity search and clustering of dense vectors.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Kota Yamaguchi <yamaguchi_kota@cyberagent.co.jp>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: numpy, packaging\n",
            "Required-by: \n",
            "---\n",
            "Name: python-dotenv\n",
            "Version: 1.1.1\n",
            "Summary: Read key-value pairs from a .env file and set them as environment variables\n",
            "Home-page: https://github.com/theskumar/python-dotenv\n",
            "Author: Saurabh Kumar\n",
            "Author-email: me+github@saurabh-kumar.com\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: \n",
            "Required-by: google-adk, pydantic-settings\n",
            "---\n",
            "Name: pypdf\n",
            "Version: 6.1.2\n",
            "Summary: A pure-python PDF library capable of splitting, merging, cropping, and transforming PDF files\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Mathieu Fenniak <biziqe@mathieu.fenniak.net>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "---\n",
            "Name: serpapi\n",
            "Version: 0.1.5\n",
            "Summary: The official Python client for SerpApi.com.\n",
            "Home-page: https://github.com/serpapi/serpapi-python\n",
            "Author: SerpApi.com\n",
            "Author-email: kenneth@serpapi.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: requests\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show langchain langchain-community langchain_google_genai langchain-core faiss-cpu python-dotenv pypdf serpapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4FfwLZMWwqO8"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "# from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.messages import AIMessage,ToolMessage\n",
        "import json\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qWHjqroExz5K"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "# Load Gemini API key from Colab secrets\n",
        "GOOGLE_API_KEY=userdata.get('GEMINI_API_KEY')\n",
        "SERPAPI_API_KEY=userdata.get('SERPAPI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mGFiILUQxQNk"
      },
      "outputs": [],
      "source": [
        "messages = []\n",
        "\n",
        "# ✅ Load API key\n",
        "# load_dotenv()\n",
        "# SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\") # Removed\n",
        "if not SERPAPI_API_KEY: # Changed to use the variable loaded from Colab secrets\n",
        "    raise ValueError(\"❌ SERPAPI_API_KEY not found. Please check your .env file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5YE7kviSyzgo"
      },
      "outputs": [],
      "source": [
        "# ✅ Load and process PDF\n",
        "pdf_path = \"/content/scholarship_info.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SW_WIGDz0HNJ"
      },
      "outputs": [],
      "source": [
        "# ✅ Set up LLM and RAG chain\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "krUyRled0SVm"
      },
      "outputs": [],
      "source": [
        "# ✅ Define tools using modern `@tool` decorator\n",
        "@tool\n",
        "def pdf_scholarship_search(query: str) -> str:\n",
        "    \"\"\"Answer scholarship-related questions using the loaded PDF.\"\"\"\n",
        "    return rag_chain.invoke(query)[\"result\"]\n",
        "\n",
        "# @tool\n",
        "# def web_search(query: str) -> str:\n",
        "#     \"\"\"Search the web using SerpAPI for up-to-date information.\"\"\"\n",
        "#     search = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)\n",
        "#     return search.run(query)\n",
        "@tool\n",
        "def web_search(query: str) -> str:\n",
        "    \"\"\"Search the web using SerpAPI for up-to-date information.\"\"\"\n",
        "    try:\n",
        "        search = SerpAPIWrapper()\n",
        "        return search.run(query)\n",
        "    except Exception as e:\n",
        "        return f\"❌ Failed to search the web: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sd3bV2IN0TIY"
      },
      "outputs": [],
      "source": [
        "# ✅ Bind tools to LLM\n",
        "llm_with_tools = llm.bind_tools([pdf_scholarship_search, web_search])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ney64kuL0W8Z",
        "outputId": "e70bd845-0b25-40df-f929-306e7b590f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎓 Welcome to the Scholarship Assistant!\n",
            "Type your question below (or type 'exit' to quit):\n",
            "\n",
            "🧠 Your question: For whom is this scholarship available?\n",
            "\n",
            "📌 Answer:\n",
            "This scholarship is available for students in India who are pursuing undergraduate degrees, have an annual family income below ₹6,00,000, and scored a minimum of 60% marks in their last qualifying exam.\n",
            "\n",
            "🧠 Your question: How much is the scholarship?\n",
            "\n",
            "📌 Answer:\n",
            "The scholarship offers ₹10,000 per semester for tuition and a book allowance of ₹3,000 per year.\n",
            "\n",
            "🧠 Your question: quit\n",
            "👋 Exiting. Good luck with your scholarships!\n"
          ]
        }
      ],
      "source": [
        "# ✅ Interactive loop\n",
        "print(\"\\n🎓 Welcome to the Scholarship Assistant!\")\n",
        "print(\"Type your question below (or type 'exit' to quit):\")\n",
        "\n",
        "messages = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\n🧠 Your question: \").strip()\n",
        "\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"👋 Exiting. Good luck with your scholarships!\")\n",
        "        break\n",
        "\n",
        "    # 1. Add user input\n",
        "    messages.append(HumanMessage(content=user_input))\n",
        "\n",
        "    # 2. LLM decides what to do\n",
        "    ai_message = llm_with_tools.invoke(messages)\n",
        "    messages.append(ai_message)\n",
        "\n",
        "    # 3. If tool call, run tool and append result\n",
        "    if ai_message.tool_calls:\n",
        "        for call in ai_message.tool_calls:\n",
        "            tool_name = call[\"name\"]\n",
        "            tool_args = call[\"args\"]\n",
        "\n",
        "            if tool_name == \"web_search\":\n",
        "                tool_output = web_search.invoke(tool_args)\n",
        "            elif tool_name == \"pdf_scholarship_search\":\n",
        "                tool_output = pdf_scholarship_search.invoke(tool_args)\n",
        "            else:\n",
        "                tool_output = f\"Unknown tool: {tool_name}\"\n",
        "\n",
        "            # 4. Append tool result as a message\n",
        "            messages.append(ToolMessage(tool_call_id=call[\"id\"], content=tool_output))\n",
        "\n",
        "        # 5. Ask LLM to give final answer using tool result\n",
        "        final_response = llm_with_tools.invoke(messages)\n",
        "        print(\"\\n📌 Answer:\")\n",
        "        print(final_response.content)\n",
        "        messages.append(final_response)\n",
        "\n",
        "    else:\n",
        "        # No tool needed — just print answer\n",
        "        print(\"\\n📌 Answer:\")\n",
        "        print(ai_message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG0DzUxcPwzg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
