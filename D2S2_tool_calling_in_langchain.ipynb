{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYZtA71kZqF8"
      },
      "source": [
        "Set the environment variable for the Groq API key to authenticate requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU8SV0vQQNbH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"[YOUR_GROQ_API_KEY]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQvK7zJNZqF_"
      },
      "source": [
        "Install the necessary Python packages: `langchain-groq`, `langchain-core`, and `requests`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhsAIGxgQh2H",
        "outputId": "87ab3bb7-26cd-44ba-a6a9-ed5495613f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-groq langchain-core requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4w7GE7DZqF_"
      },
      "source": [
        "Import the required modules from LangChain and the `requests` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uWMBgyx1Q3Ek"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbcmFc1CZqGA"
      },
      "source": [
        "Create a simple tool using the `@tool` decorator that multiplies two numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ppi8jSXxT6EA"
      },
      "outputs": [],
      "source": [
        "# tool create\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "  \"\"\"Given 2 numbers a and b this tool returns their product\"\"\"\n",
        "  return a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh1J40jbZqGA"
      },
      "source": [
        "Invoke the `multiply` tool with sample arguments to test its functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-eRpimtrUgc",
        "outputId": "7bebb461-4953-4d29-9694-41489cc10ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n"
          ]
        }
      ],
      "source": [
        "print(multiply.invoke({'a':3, 'b':4}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tOjRDN8ZqGB"
      },
      "source": [
        "Display the name of the `multiply` tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SSi7Xn0jrZ5Y",
        "outputId": "cb0e8d46-173d-46f0-cc11-24be9dd61600"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'multiply'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiMHie-WZqGB"
      },
      "source": [
        "Display the description of the `multiply` tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vNcN0ngarb9c",
        "outputId": "66a430c5-de65-4062-c39c-2a1634fafd43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Given 2 numbers a and b this tool returns their product'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pypkmUieZqGB"
      },
      "source": [
        "Display the argument schema for the `multiply` tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZdJuKhWrd6w",
        "outputId": "4c285139-062e-4863-d55a-07e1910156b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': {'title': 'A', 'type': 'integer'},\n",
              " 'b': {'title': 'B', 'type': 'integer'}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dF6yzEiurfiA"
      },
      "outputs": [],
      "source": [
        "# tool binding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfVGNAm1ZqGC"
      },
      "source": [
        "Create a ChatGroq language model instance with a specified model and temperature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "goFX0Z4PrjN7"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(model=\"openai/gpt-oss-20b\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k00_BBOSZqGC"
      },
      "source": [
        "Invoke the LLM with a simple greeting to test its response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4srYldghox9V",
        "outputId": "699e0a22-100d-4079-a081-01f78869d29d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'reasoning_content': 'The user says \"hi\". We need to respond. The instruction: \"You are ChatGPT, a large language model trained by OpenAI.\" There\\'s no special instruction. Just respond politely.'}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 72, 'total_tokens': 129, 'completion_time': 0.058765177, 'prompt_time': 0.003969963, 'queue_time': 0.212691016, 'total_time': 0.06273514}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3d587a02fb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--75961398-481d-476c-b5c7-a8711bd6ce1e-0', usage_metadata={'input_tokens': 72, 'output_tokens': 57, 'total_tokens': 129})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke('hi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8QJVpJfZqGD"
      },
      "source": [
        "Bind the `multiply` tool to the LLM so it can use the tool during conversations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v3x5N-V6rlHe"
      },
      "outputs": [],
      "source": [
        "llm_with_tools = llm.bind_tools([multiply])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsqo2pk6ZqGD"
      },
      "source": [
        "Invoke the LLM with tools enabled using a simple greeting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aLDyLhnrrxu",
        "outputId": "6fa137da-48ea-47e9-f29b-8e0367e6933b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello! I'm just a bunch of code, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", additional_kwargs={'reasoning_content': 'User says \"Hi how are you\". We respond politely.'}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 133, 'total_tokens': 186, 'completion_time': 0.0550846, 'prompt_time': 0.006773302, 'queue_time': 0.211471088, 'total_time': 0.061857902}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2f8622f6-fe9b-468a-82d8-f4933f531261-0', usage_metadata={'input_tokens': 133, 'output_tokens': 53, 'total_tokens': 186})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_with_tools.invoke('Hi how are you')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPFLtrXkZqGD"
      },
      "source": [
        "Create a `HumanMessage` asking the LLM to multiply two numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0EEB2dwtzXmS"
      },
      "outputs": [],
      "source": [
        "query = HumanMessage('can you multiply 3 with 1000')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTg0Lr6RZqGD"
      },
      "source": [
        "Initialize a list of messages to be used in the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nNAUAM_Szb27"
      },
      "outputs": [],
      "source": [
        "messages = [query]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teCd19EzZqGE"
      },
      "source": [
        "Display the current list of messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n2U76sWzh1T",
        "outputId": "92b5d96c-4d36-4a62-ff63-a2ce57d11439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='can you multiply 3 with 1000', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cgrAxOVZqGE"
      },
      "source": [
        "Invoke the LLM with the prepared messages and tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vXk2J6QXuaTM"
      },
      "outputs": [],
      "source": [
        "result = llm_with_tools.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkPIimpaZqGE"
      },
      "source": [
        "Append the AI's response to the messages list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wXBI8YbUynm4"
      },
      "outputs": [],
      "source": [
        "messages.append(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPXkh2yZqGE"
      },
      "source": [
        "Display the updated list of messages after appending the AI response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVRqi5IUzqRO",
        "outputId": "17e057bd-9eb8-497a-daa2-4f75e81f82bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='can you multiply 3 with 1000', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to use the multiply function.', 'tool_calls': [{'id': 'fc_925880de-aedf-49c6-b978-6d289ad6746e', 'function': {'arguments': '{\"a\":3,\"b\":1000}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 138, 'total_tokens': 174, 'completion_time': 0.036223392, 'prompt_time': 0.006609553, 'queue_time': 0.212023606, 'total_time': 0.042832945}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_c5a89987dc', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d089ad3d-4bc1-4a0e-a55a-e1ba3d463fbd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 1000}, 'id': 'fc_925880de-aedf-49c6-b978-6d289ad6746e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 138, 'output_tokens': 36, 'total_tokens': 174})]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcaXfYRJZqGF"
      },
      "source": [
        "Invoke the `multiply` tool using the arguments extracted from the AI's tool call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vBWmBt2cukKY"
      },
      "outputs": [],
      "source": [
        "tool_result = multiply.invoke(result.tool_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88JrSSRQZqGL"
      },
      "source": [
        "Display the result returned by the `multiply` tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlrs709a0UYJ",
        "outputId": "82323a92-20b1-4f47-eab1-c5d96eb6031a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToolMessage(content='3000', name='multiply', tool_call_id='fc_925880de-aedf-49c6-b978-6d289ad6746e')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K39Jvpp0ZqGM"
      },
      "source": [
        "Append the tool result to the messages list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "y-22Hb_GyxBZ"
      },
      "outputs": [],
      "source": [
        "messages.append(tool_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oyPGb0JZqGN"
      },
      "source": [
        "Display the final list of messages after all steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9cOgYCYzzrY",
        "outputId": "8626beea-f412-4de6-c018-4a793e74fe37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='can you multiply 3 with 1000', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to use the multiply function.', 'tool_calls': [{'id': 'fc_925880de-aedf-49c6-b978-6d289ad6746e', 'function': {'arguments': '{\"a\":3,\"b\":1000}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 138, 'total_tokens': 174, 'completion_time': 0.036223392, 'prompt_time': 0.006609553, 'queue_time': 0.212023606, 'total_time': 0.042832945}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_c5a89987dc', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d089ad3d-4bc1-4a0e-a55a-e1ba3d463fbd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 1000}, 'id': 'fc_925880de-aedf-49c6-b978-6d289ad6746e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 138, 'output_tokens': 36, 'total_tokens': 174}),\n",
              " ToolMessage(content='3000', name='multiply', tool_call_id='fc_925880de-aedf-49c6-b978-6d289ad6746e')]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nOGQ1rnZqGO"
      },
      "source": [
        "Invoke the LLM with the full conversation and display its final response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ElWievBEz0nt",
        "outputId": "e4ceec08-8142-4d10-fedd-cf8d933bec24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sure! 3 × 1000 = **3000**.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_with_tools.invoke(messages).content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QINmBkF8ZqGO"
      },
      "source": [
        "Define two tools: one to fetch the currency conversion factor using an API, and another to convert a value using the conversion rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6fTZVbSz9x_"
      },
      "outputs": [],
      "source": [
        "# tool create\n",
        "from langchain_core.tools import InjectedToolArg\n",
        "from typing import Annotated\n",
        "\n",
        "@tool\n",
        "def get_conversion_factor(base_currency: str, target_currency: str) -> float:\n",
        "  \"\"\"\n",
        "  This function fetches the currency conversion factor between a given base currency and a target currency\n",
        "  \"\"\"\n",
        "  url = f'https://v6.exchangerate-api.com/v6/c754eab14ffab33112e380ca/pair/{base_currency}/{target_currency}'\n",
        "\n",
        "  response = requests.get(url)\n",
        "\n",
        "  return response.json()\n",
        "\n",
        "@tool\n",
        "def convert(base_currency_value: int, conversion_rate: Annotated[float, InjectedToolArg]) -> float:\n",
        "  \"\"\"\n",
        "  given a currency conversion rate this function calculates the target currency value from a given base currency value\n",
        "  \"\"\"\n",
        "\n",
        "  return base_currency_value * conversion_rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY8XAQ3MZqGO"
      },
      "source": [
        "Display the argument schema for the `convert` tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNIqtU-_DDVv",
        "outputId": "bfb8ded7-a6d0-4b0f-f6ef-7053e99aa5e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'base_currency_value': {'title': 'Base Currency Value', 'type': 'integer'},\n",
              " 'conversion_rate': {'title': 'Conversion Rate', 'type': 'number'}}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convert.args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH9ok1kgZqGP"
      },
      "source": [
        "Invoke the `get_conversion_factor` tool with sample currencies to test its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO_FhilZ-DYS",
        "outputId": "b8d24961-b74b-44d4-fdb8-69c1e4168741"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 'success',\n",
              " 'documentation': 'https://www.exchangerate-api.com/docs',\n",
              " 'terms_of_use': 'https://www.exchangerate-api.com/terms',\n",
              " 'time_last_update_unix': 1760486401,\n",
              " 'time_last_update_utc': 'Wed, 15 Oct 2025 00:00:01 +0000',\n",
              " 'time_next_update_unix': 1760572801,\n",
              " 'time_next_update_utc': 'Thu, 16 Oct 2025 00:00:01 +0000',\n",
              " 'base_code': 'USD',\n",
              " 'target_code': 'INR',\n",
              " 'conversion_rate': 88.8152}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_conversion_factor.invoke({'base_currency':'USD','target_currency':'INR'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH3r4ibhZqGP"
      },
      "source": [
        "Invoke the `convert` tool with sample values to test its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z25u1BbW-G8A",
        "outputId": "e048afe5-2c39-4efe-fc58-3f09723119b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "851.5999999999999"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convert.invoke({'base_currency_value':10, 'conversion_rate':85.16})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT_Qvq78ZqGP"
      },
      "source": [
        "Bind the currency conversion tools to a new LLM instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NzoScebe_ROV"
      },
      "outputs": [],
      "source": [
        "# tool binding\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-20b\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEcIJNs7ZqGP"
      },
      "source": [
        "Bind the `get_conversion_factor` and `convert` tools to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "l-tazhPJ_gQQ"
      },
      "outputs": [],
      "source": [
        "llm_with_tools = llm.bind_tools([get_conversion_factor, convert])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdqp6BOlZqGQ"
      },
      "source": [
        "Create a `HumanMessage` asking for the conversion factor and to convert a value between INR and USD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "l8yTOagt_lv6"
      },
      "outputs": [],
      "source": [
        "messages = [HumanMessage('What is the conversion factor between INR and USD, and based on that can you convert 10 inr to usd')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTCuq62MZqGQ"
      },
      "source": [
        "Display the current list of messages for the currency conversion task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09KThK4Q_xeG",
        "outputId": "5708226e-f4c0-410d-a528-469332a0a4f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the conversion factor between INR and USD, and based on that can you convert 10 inr to usd', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldWiJdSIZqGQ"
      },
      "source": [
        "Invoke the LLM with the currency conversion query and tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lYlRZBnv_ySh"
      },
      "outputs": [],
      "source": [
        "ai_message = llm_with_tools.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAP5K0jbZqGQ"
      },
      "source": [
        "Append the AI's response to the messages list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Q5queI56Xy-m"
      },
      "outputs": [],
      "source": [
        "messages.append(ai_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vU635fhZqGR"
      },
      "source": [
        "Display the tool calls suggested by the AI in its response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwqtztEJ_38D",
        "outputId": "192e3259-3bda-40aa-eb3c-f5149956469d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'get_conversion_factor',\n",
              "  'args': {'base_currency': 'INR', 'target_currency': 'USD'},\n",
              "  'id': 'fc_034e32db-cf22-4125-9cc1-a9bf4e5d71da',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_message.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E0DC7KhZqGR"
      },
      "source": [
        "Iterate through the tool calls, execute them, and update the messages list with the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1RiGaE63Iai5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "for tool_call in ai_message.tool_calls:\n",
        "  # execute the 1st tool and get the value of conversion rate\n",
        "  if tool_call['name'] == 'get_conversion_factor':\n",
        "    tool_message1 = get_conversion_factor.invoke(tool_call)\n",
        "    # fetch this conversion rate\n",
        "    conversion_rate = json.loads(tool_message1.content)['conversion_rate']\n",
        "    # append this tool message to messages list\n",
        "    messages.append(tool_message1)\n",
        "  # execute the 2nd tool using the conversion rate from tool 1\n",
        "  if tool_call['name'] == 'convert':\n",
        "    # fetch the current arg\n",
        "    tool_call['args']['conversion_rate'] = conversion_rate\n",
        "    tool_message2 = convert.invoke(tool_call)\n",
        "    messages.append(tool_message2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNahfLC8ZqGR"
      },
      "source": [
        "Display the updated list of messages after executing the tool calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZVYEJ1tUUQH",
        "outputId": "fcc7c64c-688d-4d1c-923c-1a9f4ea9c26d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the conversion factor between INR and USD, and based on that can you convert 10 inr to usd', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to use function get_conversion_factor to get factor between INR and USD. Then use convert to convert 10 INR to USD. The convert function expects base_currency_value: number. But we need to specify base_currency? The function signature: convert(_:{base_currency_value: number,}) => any. It doesn\\'t specify target currency. Maybe the context is that the conversion factor is already known? Actually convert likely uses the previously fetched conversion factor. But we need to call get_conversion_factor first. Then call convert with base_currency_value: 10. But we need to pass target currency? The function signature doesn\\'t include target_currency. Maybe the convert function uses the last fetched conversion factor. So we call get_conversion_factor with base_currency: \"INR\", target_currency: \"USD\". Then call convert with base_currency_value: 10. That should return the converted value. We\\'ll do that.', 'tool_calls': [{'id': 'fc_034e32db-cf22-4125-9cc1-a9bf4e5d71da', 'function': {'arguments': '{\"base_currency\":\"INR\",\"target_currency\":\"USD\"}', 'name': 'get_conversion_factor'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 212, 'prompt_tokens': 196, 'total_tokens': 408, 'completion_time': 0.210632508, 'prompt_time': 0.01113734, 'queue_time': 0.213154639, 'total_time': 0.221769848}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--aea66568-e333-44d7-99cf-767a9c2563bd-0', tool_calls=[{'name': 'get_conversion_factor', 'args': {'base_currency': 'INR', 'target_currency': 'USD'}, 'id': 'fc_034e32db-cf22-4125-9cc1-a9bf4e5d71da', 'type': 'tool_call'}], usage_metadata={'input_tokens': 196, 'output_tokens': 212, 'total_tokens': 408}),\n",
              " ToolMessage(content='{\"result\": \"success\", \"documentation\": \"https://www.exchangerate-api.com/docs\", \"terms_of_use\": \"https://www.exchangerate-api.com/terms\", \"time_last_update_unix\": 1760486401, \"time_last_update_utc\": \"Wed, 15 Oct 2025 00:00:01 +0000\", \"time_next_update_unix\": 1760572801, \"time_next_update_utc\": \"Thu, 16 Oct 2025 00:00:01 +0000\", \"base_code\": \"INR\", \"target_code\": \"USD\", \"conversion_rate\": 0.01126}', name='get_conversion_factor', tool_call_id='fc_034e32db-cf22-4125-9cc1-a9bf4e5d71da')]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G39drUhZqGR"
      },
      "source": [
        "Invoke the LLM with the full conversation and display its final response for the currency conversion task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Nit6VQf8Xo0A",
        "outputId": "c5065943-0888-4090-9a20-96576d30bb11"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'**Conversion factor (INR → USD):** 1\\u202fINR = **0.01126\\u202fUSD**\\n\\n**10\\u202fINR in USD:**\\n\\n\\\\[\\n10 \\\\text{\\u202fINR} \\\\times 0.01126 \\\\frac{\\\\text{USD}}{\\\\text{INR}} = 0.1126 \\\\text{\\u202fUSD}\\n\\\\]\\n\\nSo, 10\\u202fINR is approximately **$0.11 USD**.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_with_tools.invoke(messages).content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A-v2xiUZqGS"
      },
      "source": [
        "Initialize a LangChain agent using the structured chat zero-shot ReAct pattern and bind the currency tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS59eqAbX-9d",
        "outputId": "97f00f81-50bf-4b0b-a3df-2ef7c049ad11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-627313024.py:4: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent_executor = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# Step 5: Initialize the Agent ---\n",
        "agent_executor = initialize_agent(\n",
        "    tools=[get_conversion_factor, convert],\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # using ReAct pattern\n",
        "    verbose=True  # shows internal thinking\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQGIWYW_ZqGS"
      },
      "source": [
        "Run the agent with a sample user query and display the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcZBabKrTraN",
        "outputId": "e3a1a0ec-4e59-4d9d-8d36-8a785e074e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# --- Step 6: Run the Agent ---\n",
        "user_query = \"Hi how are you?\"\n",
        "\n",
        "response = agent_executor.invoke({\"input\": user_query})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
