{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# âœ‚ï¸ Session 4: Text Splitting & Preprocessing (Groq + v3)\n",
        "\n",
        "**Objective:**  \n",
        "Learn how to split large documents into smaller chunks using `RecursiveCharacterTextSplitter`.  \n",
        "\n",
        "**Why This Matters:**  \n",
        "- LLMs have context length limits (e.g., 8k or 32k tokens).  \n",
        "- Splitting ensures **efficient retrieval** while preserving context.  \n",
        "- Overlap between chunks helps avoid cutting important sentences mid-way.  \n"
      ],
      "metadata": {
        "id": "HDscLMb--1Rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 1: Install Required Libraries\n",
        "We already have LangChain v3 + Groq, but weâ€™ll ensure all dependencies are in place.\n"
      ],
      "metadata": {
        "id": "DCkplRK--5Yy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik2fOcKQ-cyo",
        "outputId": "7af66587-b203-46ab-e67a-23380722c9ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.3.* langchain-groq pypdf langchain_community\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 2: Load PDF (Re-use from Previous Session)\n",
        "Upload your `scholarship_info.pdf` to Colab if not already present.\n"
      ],
      "metadata": {
        "id": "iYra3RfC_Bef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_path = \"/content/scholarship_info.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"âœ… Loaded {len(docs)} pages.\")\n"
      ],
      "metadata": {
        "id": "aRS84ZaU-_rH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16250c7b-2077-49c9-adc1-62b4107ce783"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 1 pages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 3: Split Text into Chunks\n",
        "Weâ€™ll use `RecursiveCharacterTextSplitter`.  \n",
        "Parameters:  \n",
        "- `chunk_size=1000` â†’ Max characters per chunk  \n",
        "- `chunk_overlap=200` â†’ Overlap between chunks (to preserve context)\n"
      ],
      "metadata": {
        "id": "AMpTk5Yz-8WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "splits = splitter.split_documents(docs)\n",
        "print(f\"âœ… Split into {len(splits)} chunks.\")\n",
        "\n",
        "# Preview first chunk\n",
        "print(\"\\n--- First Chunk ---\\n\")\n",
        "print(splits[0].page_content[:500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix1g2XtUAGT9",
        "outputId": "a2c7f661-0f9c-46e1-9d8f-d2df232ebe32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Split into 2 chunks.\n",
            "\n",
            "--- First Chunk ---\n",
            "\n",
            "Title: Scholarship Information 2025 \n",
            " \n",
            "1. Eligibility: \n",
            "- Open to students in India pursuing undergraduate degrees. \n",
            "- Annual family income must be below â‚¹6,00,000. \n",
            "- Minimum 60% marks in the last qualifying exam. \n",
            " \n",
            "2. Documents Required: \n",
            "- Income certificate \n",
            "- Aadhaar card \n",
            "- Bank passbook \n",
            "- Marksheet \n",
            " \n",
            "3. Deadline: October 15, 2025 \n",
            " \n",
            "4. Benefits: \n",
            "- â‚¹10,000 per semester for tuition \n",
            "- Book allowance of â‚¹3,000 per year \n",
            " \n",
            "5. How to Apply:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 4: Use Groq LLM to Summarize a Chunk\n",
        "Letâ€™s take one chunk and summarize with LLaMA-3.\n"
      ],
      "metadata": {
        "id": "MIKsdYc6AYzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Load API key\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-20b\",\n",
        "    api_key=GROQ_API_KEY,\n",
        "    temperature=0.3,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "sample_chunk = splits[0].page_content\n",
        "summary = llm.invoke(f\"Summarize this chunk in 3 bullet points:\\n\\n{sample_chunk}\")\n",
        "\n",
        "print(\"Groq LLM Summary:\\n\", summary.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDMS7gsqAZqJ",
        "outputId": "ec2d7134-cfcc-478a-a091-7aaa76a97870"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Groq LLM Summary:\n",
            " - **Who can apply?** Indian undergraduates with family income below â‚¹6,00,000 and at least 60â€¯% marks in their last qualifying exam.  \n",
            "- **Key requirements & deadline:** Submit income certificate, Aadhaar, bank passbook, and marksheet by 15â€¯Octâ€¯2025.  \n",
            "- **Benefits:** â‚¹10,000 per semester toward tuition plus a â‚¹3,000 yearly book allowance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 5: Why Chunking Matters\n",
        "Try asking the LLM about **scholarship deadlines** using:  \n",
        "1. The whole document (may fail).  \n",
        "2. A chunked + RAG pipeline (works better, next session).  \n"
      ],
      "metadata": {
        "id": "Xp-D6GXSAir4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“ Exercise\n",
        "1. Change `chunk_size` to 500 and compare number of chunks.  \n",
        "2. Change `chunk_overlap` to 0, 100, and 300 â†’ observe differences.  \n",
        "3. Write a prompt to extract **key dates** from the first 2 chunks.  \n"
      ],
      "metadata": {
        "id": "llBJJkCYApSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ Summary\n",
        "- Split PDF into manageable chunks.  \n",
        "- Learned why overlap preserves context.  \n",
        "- Summarized a chunk with Groq LLM.  \n",
        "\n",
        "**Next Notebook â†’ Vector Stores in LangChain (Embeddings + FAISS)**  \n"
      ],
      "metadata": {
        "id": "wmviiVHRArwm"
      }
    }
  ]
}