{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Session 2: Fetching LLM Responses (Groq + LangChain v3)\n",
        "\n",
        "**Objective:**  \n",
        "Learn how to call **Groq-hosted LLMs** via LangChain, run test prompts, and explore parameters.  \n",
        "\n",
        "**Why This Matters:**  \n",
        "- Groq provides ultra-low latency responses with models like **LLaMA 3** and **Mixtral**.  \n",
        "- Before diving into RAG, participants need to practice **direct LLM calls**.  \n"
      ],
      "metadata": {
        "id": "luJYm8zA71Oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 1: Install Required Libraries\n",
        "We‚Äôll install:\n",
        "- **LangChain v3**  \n",
        "- **LangChain Groq integration**  \n"
      ],
      "metadata": {
        "id": "_1zDC5OP8CP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.27 langchain-groq==0.3.8\n"
      ],
      "metadata": {
        "id": "HZLyUF1Z74Zn",
        "outputId": "d134b126-adef-46b1-e28c-d0ac0d94f7bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/135.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m133.1/135.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1xAuAe7addo",
        "outputId": "ed3aea20-24f4-4f9b-d64f-75c8fe00e0a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.27\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: \n",
            "---\n",
            "Name: langchain-groq\n",
            "Version: 0.3.8\n",
            "Summary: An integration package connecting Groq and LangChain\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: groq, langchain-core\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 2: Setup Groq API Key\n",
        "We‚Äôll fetch it securely from **Colab Secrets**.  \n",
        "\n",
        "In Colab:  \n",
        "- Go to ` Secrets ‚Üí Add new secret`  \n",
        "- Key = `GROQ_API_KEY`  \n",
        "- Value = your Groq key from [console.groq.com](https://console.groq.com/keys)\n"
      ],
      "metadata": {
        "id": "PapMQNZt8IWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Load Groq API key\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if GROQ_API_KEY:\n",
        "    print(\"‚úÖ Groq API key retrieved!\")\n",
        "else:\n",
        "    print(\"‚ùå Please add GROQ_API_KEY in Colab Secrets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s4C70Yk8Ngt",
        "outputId": "da8a115e-ccd7-4584-be06-b5388d6ae402"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Groq API key retrieved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 3: Initialize Groq LLM\n",
        "We‚Äôll use the **ChatGroq** wrapper from LangChain.\n"
      ],
      "metadata": {
        "id": "aKPC8lKi8RT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize with LLaMA-3 (you can also use mixtral-8x7b)\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-20b\",\n",
        "    api_key=GROQ_API_KEY,\n",
        "    temperature=0.7,\n",
        "    max_tokens=256\n",
        ")\n"
      ],
      "metadata": {
        "id": "JKrlQNWk8SN7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 4: Run Basic Prompts\n",
        "Test Q&A and summarization with Groq.\n"
      ],
      "metadata": {
        "id": "3W1bHvjT8mcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Q&A\n",
        "response = llm.invoke(\"What is Retrieval-Augmented Generation (RAG) in AI?\")\n",
        "print(response)\n",
        "# print(\"Groq Response 1:\\n\", response.content)\n",
        "\n",
        "# Summarization\n",
        "text = \"\"\"LangChain is a framework for building AI-powered applications.\n",
        "It provides tools for prompt management, chaining, agents, memory,\n",
        "and integrations with external APIs and vector databases.\"\"\"\n",
        "summary = llm.invoke(f\"Summarize this in 2 sentences:\\n\\n{text}\")\n",
        "print(\"\\nSummary:\\n\", summary.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hZrrrb68nTb",
        "outputId": "28c175eb-97af-4b69-875b-236cf48f8b48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='## Retrieval‚ÄëAugmented Generation (RAG) ‚Äì A Quick‚ÄëStart Guide\\n\\n> **RAG** is a hybrid AI architecture that *retrieves* relevant text from an external knowledge source and *generates* a response conditioned on that retrieved content.  \\n> It blends the strengths of **retrieval‚Äëbased systems** (accuracy, grounding) with **generative models** (fluency, flexibility).\\n\\n---\\n\\n### 1. The Core Idea\\n\\n| Step | What Happens | Why It Matters |\\n|------|--------------|----------------|\\n| **1.' additional_kwargs={'reasoning_content': 'We need to explain Retrieval-Augmented Generation. Provide overview, components, typical architecture, benefits, examples, applications. Maybe mention RAG as introduced by Facebook AI. Explain retrieval step, knowledge base, encoder, decoder, fusion. Discuss variations: dense retrieval, sparse retrieval, hybrid. Mention use in open-domain QA, chatbots, summarization, etc. Provide potential pitfalls: retrieval errors, hallucinations, latency. Provide examples: RAG-Token, RAG-Sequence. Provide references. Also mention difference from pure generative models. Provide practical usage: training, fine-tuning, vector stores. Provide code snippet? Might be too detailed. Provide summary.'} response_metadata={'token_usage': {'completion_tokens': 256, 'prompt_tokens': 84, 'total_tokens': 340, 'completion_time': 0.29383224, 'prompt_time': 0.012337885, 'queue_time': 0.326153532, 'total_time': 0.306170125}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_4f7e7dc26e', 'service_tier': 'on_demand', 'finish_reason': 'length', 'logprobs': None} id='run--8e5e070a-e3ee-48d6-b71a-86b605ed0538-0' usage_metadata={'input_tokens': 84, 'output_tokens': 256, 'total_tokens': 340}\n",
            "\n",
            "Summary:\n",
            " LangChain is a framework that empowers developers to build AI‚Äëpowered applications by offering tools for prompt management, chaining, agents, and memory. It also integrates seamlessly with external APIs and vector databases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 5: Exploring Parameters\n",
        "- `temperature` ‚Üí Randomness of output (0 = factual, 1 = creative).  \n",
        "- `max_tokens` ‚Üí Maximum response length.  \n"
      ],
      "metadata": {
        "id": "BLSJMm779EaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Low temperature (factual)\n",
        "cold = ChatGroq(model=\"openai/gpt-oss-20b\", api_key=GROQ_API_KEY, temperature=0.0)\n",
        "print(\"Cold Response:\", cold.invoke(\"Suggest one creative use of AI in education\").content)\n",
        "print(\"_\"*50)\n",
        "\n",
        "# High temperature (creative)\n",
        "hot = ChatGroq(model=\"openai/gpt-oss-20b\", api_key=GROQ_API_KEY, temperature=0.9)\n",
        "print(\"\\nHot Response:\", hot.invoke(\"Suggest one creative use of AI in education\").content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNIcUKMO9GDu",
        "outputId": "d0334435-b093-4dbc-b5fa-b005693752b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cold Response: **AI‚ÄëPowered ‚ÄúLearning Lab‚Äù ‚Äì A Dynamic, Adaptive, Collaborative Sandbox**\n",
            "\n",
            "**Concept**  \n",
            "Create a virtual ‚ÄúLearning Lab‚Äù that blends AI, mixed‚Äëreality, and real‚Äëworld data to let students design, test, and iterate on projects that span multiple subjects. Think of it as a digital science‚Äëfair, coding bootcamp, and design sprint rolled into one, but powered by AI to personalize, scaffold, and amplify creativity.\n",
            "\n",
            "**How it Works**\n",
            "\n",
            "| Feature | AI Role | Student Experience |\n",
            "|---------|---------|--------------------|\n",
            "| **Project Ideation** | Natural‚Äëlanguage generation + knowledge graph | Students type a problem statement (‚ÄúHow can we reduce plastic waste in our school?‚Äù) and the AI suggests interdisciplinary angles (biology, economics, design, coding). |\n",
            "| **Skill Gap Analysis** | Adaptive assessment + skill mapping | The AI evaluates the student‚Äôs current knowledge and recommends micro‚Äëlearning modules (videos, quizzes, interactive simulations) to fill gaps. |\n",
            "| **Collaborative Design** | Real‚Äëtime language translation + sentiment analysis | Teams from different language backgrounds can co‚Äëcreate prototypes; the AI moderates communication, highlights misunderstandings, and suggests clarifications. |\n",
            "| **Simulation & Testing** | Physics engine + predictive modeling | Students build virtual prototypes (e.g., a biodegradable packaging design) and run simulations that predict performance, cost, and environmental impact. |\n",
            "| **Feedback Loop** | Generative critique + emotional tone detection | After each iteration, the AI provides constructive feedback, celebrates progress, and nudges students toward deeper inquiry. |\n",
            "| **Real‚ÄëWorld Connection** | Data mining + API integration | The AI pulls in current news, research papers, and local statistics, allowing students to anchor their projects in real‚Äëtime data. |\n",
            "| **Showcase & Reflection** | Automated video editing + reflective prompts | The AI compiles a polished presentation video and asks reflective questions (‚ÄúWhat surprised you?‚Äù ‚ÄúWhat would you do differently?‚Äù). |\n",
            "\n",
            "**Why It‚Äôs Creative**\n",
            "\n",
            "1. **Cross‚ÄëDisciplinary Fusion** ‚Äì Students naturally weave science, math, art, and humanities into one project, mirroring real‚Äëworld problem solving.\n",
            "2. **Personalized, Adaptive Learning** ‚Äì AI tailors the learning path to each student‚Äôs strengths, interests, and pace, turning the classroom into a ‚Äúlearning ecosystem.‚Äù\n",
            "3. **Immediate, Data‚ÄëDriven Feedback** ‚Äì Instead of waiting for a teacher‚Äôs review, students receive instant, actionable insights, keeping momentum high.\n",
            "4. **Global Collaboration** ‚Äì Language translation and sentiment analysis break down barriers, letting students partner with peers worldwide.\n",
            "5. **Real‚ÄëWorld Impact** ‚Äì By integrating live data and local context, projects feel relevant and can even influence community decisions (e.g., a school‚Äôs waste‚Äëmanagement plan).\n",
            "\n",
            "**Implementation Snapshot**\n",
            "\n",
            "- **Phase 1 (Pilot)** ‚Äì 1‚Äë2 classes use the platform for a single interdisciplinary project (e.g., designing a low‚Äëcost water purifier).  \n",
            "- **Phase 2 (Scale)** ‚Äì Expand to multiple subjects, integrate with existing LMS, and add teacher dashboards for monitoring progress.  \n",
            "- **Phase 3 (Community)** ‚Äì Open the sandbox to external partners (NGOs, industry mentors) for real‚Äëworld feedback and potential funding.\n",
            "\n",
            "**Outcome**  \n",
            "Students leave the Learning Lab not only with deeper knowledge but also with a portfolio of AI‚Äëenhanced projects, collaborative skills, and a mindset that sees problems as opportunities for creative, data‚Äëdriven solutions.\n",
            "__________________________________________________\n",
            "\n",
            "Hot Response: **AI‚ÄëPowered Adaptive History Museum**\n",
            "\n",
            "Create a virtual museum that AI ‚Äúcurates‚Äù on‚Äëdemand for each student.  \n",
            "- **Dynamic Exhibit Selection** ‚Äì As a student explores a time period, the AI tracks the topics they click on, ask questions about, or spend extra time with and then pulls in the most relevant artifacts, primary documents, or multimedia clips from a huge database.  \n",
            "- **Real‚Äëtime Guided Narrative** ‚Äì Instead of a static tour guide, the AI speaks in natural language, tailoring explanations, analogies, and depth of detail to the student‚Äôs reading level, prior knowledge, and expressed interests.  \n",
            "- **Interactive Quizzes & Debates** ‚Äì After each ‚Äúroom,‚Äù the AI generates personalized quiz questions, prompts for critical thinking, or even simulates a debate with a historical figure.  \n",
            "- **Collaborative Exploration** ‚Äì Multiple students can join the same virtual walk, and the AI mediates group discussions, ensuring each voice is heard and connecting their ideas to the broader narrative.  \n",
            "\n",
            "This use turns passive textbook learning into a living, responsive experience that adapts to every student‚Äôs curiosity, making complex historical contexts engaging and personalized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Exercise\n",
        "1. Change the model compare answers.  \n",
        "2. Try summarizing a longer passage of your choice.  \n",
        "3. Ask Groq to **generate pros & cons** of using RAG vs plain LLMs.  \n"
      ],
      "metadata": {
        "id": "e2_bacxD9p6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Summary\n",
        "- Installed **LangChain v3** with Groq integration.  \n",
        "- Made simple LLM calls with `ChatGroq`.  \n",
        "- Learned how to adjust parameters (`temperature`, `max_tokens`).  \n",
        "\n",
        "**Next Notebook ‚Üí Document Loaders in LangChain**  \n"
      ],
      "metadata": {
        "id": "Ssv8lLii9uI2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}