{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 Session 2: Fetching LLM Responses (Groq + LangChain v3)\n",
        "\n",
        "**Objective:**  \n",
        "Learn how to call **Groq-hosted LLMs** via LangChain, run test prompts, and explore parameters.  \n",
        "\n",
        "**Why This Matters:**  \n",
        "- Groq provides ultra-low latency responses with models like **LLaMA 3** and **Mixtral**.  \n",
        "- Before diving into RAG, participants need to practice **direct LLM calls**.  \n"
      ],
      "metadata": {
        "id": "luJYm8zA71Oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Step 1: Install Required Libraries\n",
        "We’ll install:\n",
        "- **LangChain v3**  \n",
        "- **LangChain Groq integration**  \n"
      ],
      "metadata": {
        "id": "_1zDC5OP8CP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.* langchain-groq\n"
      ],
      "metadata": {
        "id": "HZLyUF1Z74Zn",
        "outputId": "b23a6bf8-5252-4cd2-8791-b256639efbd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Step 2: Setup Groq API Key\n",
        "We’ll fetch it securely from **Colab Secrets**.  \n",
        "\n",
        "In Colab:  \n",
        "- Go to ` Secrets → Add new secret`  \n",
        "- Key = `GROQ_API_KEY`  \n",
        "- Value = your Groq key from [console.groq.com](https://console.groq.com/keys)\n"
      ],
      "metadata": {
        "id": "PapMQNZt8IWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Load Groq API key\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if GROQ_API_KEY:\n",
        "    print(\"✅ Groq API key retrieved!\")\n",
        "else:\n",
        "    print(\"❌ Please add GROQ_API_KEY in Colab Secrets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s4C70Yk8Ngt",
        "outputId": "353fff13-bc3e-4b86-b716-5d53dbd9e9f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Groq API key retrieved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Step 3: Initialize Groq LLM\n",
        "We’ll use the **ChatGroq** wrapper from LangChain.\n"
      ],
      "metadata": {
        "id": "aKPC8lKi8RT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize with LLaMA-3 (you can also use mixtral-8x7b)\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-20b\",\n",
        "    api_key=GROQ_API_KEY,\n",
        "    temperature=0.7,\n",
        "    max_tokens=256\n",
        ")\n"
      ],
      "metadata": {
        "id": "JKrlQNWk8SN7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Step 4: Run Basic Prompts\n",
        "Test Q&A and summarization with Groq.\n"
      ],
      "metadata": {
        "id": "3W1bHvjT8mcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Q&A\n",
        "response = llm.invoke(\"What is Retrieval-Augmented Generation (RAG) in AI?\")\n",
        "print(response)\n",
        "# print(\"Groq Response 1:\\n\", response.content)\n",
        "\n",
        "# Summarization\n",
        "text = \"\"\"LangChain is a framework for building AI-powered applications.\n",
        "It provides tools for prompt management, chaining, agents, memory,\n",
        "and integrations with external APIs and vector databases.\"\"\"\n",
        "summary = llm.invoke(f\"Summarize this in 2 sentences:\\n\\n{text}\")\n",
        "print(\"\\nSummary:\\n\", summary.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hZrrrb68nTb",
        "outputId": "699bf4c4-5d67-4f9e-e86c-c6e3d1f42caf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='## Retrieval‑Augmented Generation (RAG) – A Quick‑Start Guide\\n\\n| Term | What it is | Why it matters |\\n|------|------------|----------------|\\n| **Retrieval‑Augmented Generation (RAG)** | A hybrid AI framework that **retrieves** relevant documents from a knowledge base **and** uses a language model to **generate** a response that blends that evidence with the model’s own knowledge. | It lets you keep a large, up‑to‑date knowledge store *outside* the model, giving you both the fluency of a generative LLM and the factual accuracy of a search engine. |\\n\\n---\\n\\n## 1. The Core Idea\\n\\n1. **Input** – A user query or prompt.  \\n2. **Retrieval** – Search a large corpus (e.g., Wikipedia, corporate docs, a custom knowledge base) for the most relevant passages.' additional_kwargs={'reasoning_content': 'We need to explain Retrieval-Augmented Generation (RAG) in AI. Provide overview, components, how it works, benefits, typical use cases, examples, architecture, differences from pure generation, retrieval mechanisms, training, challenges, future directions. Provide simple explanation, maybe some diagrams in text, references. Provide answer.'} response_metadata={'token_usage': {'completion_tokens': 256, 'prompt_tokens': 84, 'total_tokens': 340, 'completion_time': 0.266700218, 'prompt_time': 0.004014266, 'queue_time': 0.201394402, 'total_time': 0.270714484}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'length', 'logprobs': None} id='run--2698e3e6-abb5-4688-9cb5-6565652e5f73-0' usage_metadata={'input_tokens': 84, 'output_tokens': 256, 'total_tokens': 340}\n",
            "\n",
            "Summary:\n",
            " LangChain is a framework for building AI‑powered applications, offering tools for prompt management, chaining, agents, and memory. It also supports integrations with external APIs and vector databases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Step 5: Exploring Parameters\n",
        "- `temperature` → Randomness of output (0 = factual, 1 = creative).  \n",
        "- `max_tokens` → Maximum response length.  \n"
      ],
      "metadata": {
        "id": "BLSJMm779EaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Low temperature (factual)\n",
        "cold = ChatGroq(model=\"openai/gpt-oss-20b\", api_key=GROQ_API_KEY, temperature=0.0)\n",
        "print(\"Cold Response:\", cold.invoke(\"Suggest one creative use of AI in education\").content)\n",
        "print(\"_\"*50)\n",
        "\n",
        "# High temperature (creative)\n",
        "hot = ChatGroq(model=\"openai/gpt-oss-20b\", api_key=GROQ_API_KEY, temperature=0.9)\n",
        "print(\"\\nHot Response:\", hot.invoke(\"Suggest one creative use of AI in education\").content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNIcUKMO9GDu",
        "outputId": "f766f964-a686-4ca7-ce44-847f8f83d3b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cold Response: **AI‑Generated Interactive Storytelling Lab**\n",
            "\n",
            "**What it is**  \n",
            "A classroom‑ready, AI‑driven platform that turns every student into a co‑author of a living, breathing narrative. Students start with a simple prompt (e.g., “a lost robot in a city of dreams”), and the AI writes the first chapter, suggests plot twists, generates character backstories, and even creates accompanying illustrations or short animations. Students can then edit, add dialogue, or branch the story into multiple paths, and the AI adapts its suggestions in real time.\n",
            "\n",
            "**How it works**  \n",
            "\n",
            "| Step | What happens | AI’s role |\n",
            "|------|--------------|-----------|\n",
            "| 1. Prompt & Goal | Students choose a genre, theme, or learning objective (e.g., “explore the concept of empathy”). | AI parses the prompt and aligns it with the learning goal. |\n",
            "| 2. Draft Generation | AI writes an opening scene, complete with setting, characters, and conflict. | Uses large‑language‑model (LLM) to produce coherent, age‑appropriate prose. |\n",
            "| 3. Visual & Audio Layer | AI generates illustrations, soundscapes, or short video clips that match the text. | Employs multimodal generation models (e.g., DALL‑E, Stable Diffusion, text‑to‑speech). |\n",
            "| 4. Student Interaction | Students edit the text, add dialogue, or choose a branching decision point. | AI updates the narrative flow, ensuring continuity and logical consistency. |\n",
            "| 5. Feedback & Reflection | AI provides targeted feedback on language use, narrative structure, and alignment with the learning objective. | Uses natural‑language‑processing (NLP) to analyze student edits and suggest improvements. |\n",
            "| 6. Collaboration | Multiple students can co‑author the same story, each contributing a chapter or a character arc. | AI merges contributions, resolves conflicts, and maintains a unified storyline. |\n",
            "\n",
            "**Why it’s creative and powerful**\n",
            "\n",
            "- **Personalized Creativity**: Every student’s story can be tailored to their interests, learning style, and skill level.  \n",
            "- **Multimodal Learning**: Combines reading, writing, visual arts, and even basic coding (for branching logic).  \n",
            "- **Immediate, Contextual Feedback**: AI highlights narrative strengths and weaknesses in real time, encouraging iterative improvement.  \n",
            "- **Inclusive & Accessible**: Students with writing difficulties or language barriers receive scaffolded support, while advanced writers can push boundaries.  \n",
            "- **Cross‑Curricular**: The platform can embed science concepts (e.g., robotics), history (e.g., time‑travel), or math (e.g., puzzle‑based plot twists).  \n",
            "\n",
            "**Example in a 5th‑grade classroom**\n",
            "\n",
            "1. **Prompt**: “A time‑traveling backpack that takes students to the age of dinosaurs.”  \n",
            "2. **AI writes** the opening scene, introduces the backpack, and sets up a mystery.  \n",
            "3. **Students** choose whether the backpack is friendly or mischievous, add dialogue, and decide the next destination.  \n",
            "4. **AI** generates a dinosaur illustration and a short audio clip of a roar.  \n",
            "5. **Feedback**: AI points out a missing transition and suggests a stronger hook.  \n",
            "6. **Collaboration**: Two groups merge their stories into a single adventure, learning to negotiate plot coherence.  \n",
            "\n",
            "**Outcome**  \n",
            "Students finish a polished, multimedia story that demonstrates narrative structure, vocabulary growth, and critical thinking—all while having fun co‑creating with an AI partner. This creative use of AI turns storytelling from a solitary task into a dynamic, collaborative, and deeply engaging learning experience.\n",
            "__________________________________________________\n",
            "\n",
            "Hot Response: **AI‑Powered Immersive Virtual Field Trips**\n",
            "\n",
            "Create a system where a generative‑AI model constructs fully interactive, location‑specific virtual field trips on demand. Students “visit” a site by chatting with an AI guide that pulls real‑time data (maps, weather, local news) and blends it with historical facts, 3‑D visuals, and sensory cues (sound, light effects). The AI can:\n",
            "\n",
            "1. **Adapt the experience** to each learner’s knowledge level and interests (e.g., a biology student gets a deeper dive into the coral reef’s ecosystem, while an art student sees the architecture).\n",
            "2. **Facilitate guided inquiry** by asking open‑ended questions, prompting reflection, and providing instant feedback or supplemental resources.\n",
            "3. **Integrate assessment** by tracking engagement metrics (time spent on sections, responses to prompts) and generating a dynamic quiz that adjusts difficulty in real time.\n",
            "4. **Encourage collaboration** by letting multiple students share the same virtual space, each with their own AI guide that can coordinate group tasks or debates.\n",
            "\n",
            "**Why it’s creative**  \n",
            "- It turns passive lecture content into an explorative, multi‑sensory adventure that feels like a real trip.\n",
            "- It uses AI to blend up‑to‑date data, historical context, and personalized learning pathways in one seamless experience.\n",
            "- It scales: any location (the Louvre, the Amazon, the International Space Station) can become a classroom without travel costs or logistical constraints.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📝 Exercise\n",
        "1. Change the model compare answers.  \n",
        "2. Try summarizing a longer passage of your choice.  \n",
        "3. Ask Groq to **generate pros & cons** of using RAG vs plain LLMs.  \n"
      ],
      "metadata": {
        "id": "e2_bacxD9p6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎯 Summary\n",
        "- Installed **LangChain v3** with Groq integration.  \n",
        "- Made simple LLM calls with `ChatGroq`.  \n",
        "- Learned how to adjust parameters (`temperature`, `max_tokens`).  \n",
        "\n",
        "**Next Notebook → Document Loaders in LangChain**  \n"
      ],
      "metadata": {
        "id": "Ssv8lLii9uI2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}