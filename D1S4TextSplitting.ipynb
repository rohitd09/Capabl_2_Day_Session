{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# âœ‚ï¸ Session 4: Text Splitting & Preprocessing (Groq + v3)\n",
        "\n",
        "**Objective:**  \n",
        "Learn how to split large documents into smaller chunks using `RecursiveCharacterTextSplitter`.  \n",
        "\n",
        "**Why This Matters:**  \n",
        "- LLMs have context length limits (e.g., 8k or 32k tokens).  \n",
        "- Splitting ensures **efficient retrieval** while preserving context.  \n",
        "- Overlap between chunks helps avoid cutting important sentences mid-way.  \n"
      ],
      "metadata": {
        "id": "HDscLMb--1Rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 1: Install Required Libraries\n",
        "We already have LangChain v3 + Groq, but weâ€™ll ensure all dependencies are in place.\n"
      ],
      "metadata": {
        "id": "DCkplRK--5Yy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik2fOcKQ-cyo",
        "outputId": "d25b5be6-228a-42d8-df26-c28143418b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m864.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.3.27 langchain-groq==0.3.8 pypdf==6.1.2 langchain_community==0.3.31\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain langchain-groq pypdf langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fOWXNBIkWGp",
        "outputId": "88383929-87e2-47eb-a185-d953497e3c6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.27\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: langchain-community\n",
            "---\n",
            "Name: langchain-groq\n",
            "Version: 0.3.8\n",
            "Summary: An integration package connecting Groq and LangChain\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: groq, langchain-core\n",
            "Required-by: \n",
            "---\n",
            "Name: pypdf\n",
            "Version: 6.1.2\n",
            "Summary: A pure-python PDF library capable of splitting, merging, cropping, and transforming PDF files\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Mathieu Fenniak <biziqe@mathieu.fenniak.net>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "---\n",
            "Name: langchain-community\n",
            "Version: 0.3.31\n",
            "Summary: Community contributed LangChain integrations.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 2: Load PDF (Re-use from Previous Session)\n",
        "Upload your `scholarship_info.pdf` to Colab if not already present.\n"
      ],
      "metadata": {
        "id": "iYra3RfC_Bef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_path = \"/content/scholarship_info.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"âœ… Loaded {len(docs)} pages.\")\n"
      ],
      "metadata": {
        "id": "aRS84ZaU-_rH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de6a883-a377-4fe4-878e-0d8eb385029e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 1 pages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 3: Split Text into Chunks\n",
        "Weâ€™ll use `RecursiveCharacterTextSplitter`.  \n",
        "Parameters:  \n",
        "- `chunk_size=1000` â†’ Max characters per chunk  \n",
        "- `chunk_overlap=200` â†’ Overlap between chunks (to preserve context)\n"
      ],
      "metadata": {
        "id": "AMpTk5Yz-8WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "splits = splitter.split_documents(docs)\n",
        "print(f\"âœ… Split into {len(splits)} chunks.\")\n",
        "\n",
        "# Preview first chunk\n",
        "print(\"\\n--- First Chunk ---\\n\")\n",
        "print(splits[0].page_content[:500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix1g2XtUAGT9",
        "outputId": "0d6f7cd9-34c9-46ae-c4fa-8a708817f97a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Split into 2 chunks.\n",
            "\n",
            "--- First Chunk ---\n",
            "\n",
            "Title: Scholarship Information 2025 \n",
            " \n",
            "1. Eligibility: \n",
            "- Open to students in India pursuing undergraduate degrees. \n",
            "- Annual family income must be below â‚¹6,00,000. \n",
            "- Minimum 60% marks in the last qualifying exam. \n",
            " \n",
            "2. Documents Required: \n",
            "- Income certificate \n",
            "- Aadhaar card \n",
            "- Bank passbook \n",
            "- Marksheet \n",
            " \n",
            "3. Deadline: October 15, 2025 \n",
            " \n",
            "4. Benefits: \n",
            "- â‚¹10,000 per semester for tuition \n",
            "- Book allowance of â‚¹3,000 per year \n",
            " \n",
            "5. How to Apply:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 4: Use Groq LLM to Summarize a Chunk\n",
        "Letâ€™s take one chunk and summarize with LLaMA-3.\n"
      ],
      "metadata": {
        "id": "MIKsdYc6AYzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Load API key\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-20b\",\n",
        "    api_key=GROQ_API_KEY,\n",
        "    temperature=0.3,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "sample_chunk = splits[0].page_content\n",
        "summary = llm.invoke(f\"Summarize this chunk in 3 bullet points:\\n\\n{sample_chunk}\")\n",
        "\n",
        "print(\"Groq LLM Summary:\\n\", summary.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDMS7gsqAZqJ",
        "outputId": "f34398ce-9684-4d70-a4cb-645b75067d8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Groq LLM Summary:\n",
            " - **Eligibility & Application**: Open to Indian undergraduates with family income <â€¯â‚¹6,00,000 and â‰¥â€¯60â€¯% marks; must submit income certificate, Aadhaar, bank passbook, and marksheet by the Octoberâ€¯15,â€¯2025 deadline.  \n",
            "- **Benefits**: Receives â‚¹10,000 per semester toward tuition and a â‚¹3,000 annual book allowance.  \n",
            "- **Process**: Apply online (details not provided) using the required documents and meeting the stated criteria.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Step 5: Why Chunking Matters\n",
        "Try asking the LLM about **scholarship deadlines** using:  \n",
        "1. The whole document (may fail).  \n",
        "2. A chunked + RAG pipeline (works better, next session).  \n"
      ],
      "metadata": {
        "id": "Xp-D6GXSAir4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“ Exercise\n",
        "1. Change `chunk_size` to 500 and compare number of chunks.  \n",
        "2. Change `chunk_overlap` to 0, 100, and 300 â†’ observe differences.  \n",
        "3. Write a prompt to extract **key dates** from the first 2 chunks.  \n"
      ],
      "metadata": {
        "id": "llBJJkCYApSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ Summary\n",
        "- Split PDF into manageable chunks.  \n",
        "- Learned why overlap preserves context.  \n",
        "- Summarized a chunk with Groq LLM.  \n",
        "\n",
        "**Next Notebook â†’ Vector Stores in LangChain (Embeddings + FAISS)**  \n"
      ],
      "metadata": {
        "id": "wmviiVHRArwm"
      }
    }
  ]
}